import os
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from typing import TypedDict, Annotated

from config import OPENAI_API_KEY, OPENAI_API_BASE
from text_to_image import TextToImageGenerator, create_image_prompt

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
llm = ChatOpenAI(
    temperature=0.7, model="gpt-4o-mini", openai_api_base=OPENAI_API_BASE
)


# ===== 1. æ‰©å±•çŠ¶æ€ç»“æ„ =====
class ContentState(TypedDict):
    """å†…å®¹åˆ›ä½œå·¥ä½œæµçš„çŠ¶æ€å®¹å™¨"""
    topic: str  # ç”¨æˆ·è¾“å…¥çš„ä¸»é¢˜
    draft: str  # æ–‡å­—è‰ç¨¿
    corrections: list[str]  # æ–‡å­—ä¿®æ­£è®°å½•
    image_prompt: str  # å›¾ç‰‡ç”Ÿæˆæç¤ºè¯
    image_paths: list[str]  # ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„
    attempts: int  # å°è¯•æ¬¡æ•°


# ===== 2. åˆ›å»ºèŠ‚ç‚¹å‡½æ•° =====
def generate_content_draft(state: ContentState):
    """æ ¹æ®ä¸»é¢˜ç”Ÿæˆå†…å®¹è‰ç¨¿"""
    prompt = PromptTemplate.from_template(
        "è¯·ä¸º{topic}å†™ä¸€æ®µè¯¦ç»†çš„å†…å®¹ä»‹ç»ï¼ŒåŒ…å«ä»¥ä¸‹è¦ç´ ï¼š\n"
        "1. åŸºæœ¬ä»‹ç»å’ŒèƒŒæ™¯\n"
        "2. ä¸»è¦ç‰¹ç‚¹æˆ–ä¼˜åŠ¿\n"
        "3. å®é™…åº”ç”¨åœºæ™¯\n"
        "4. ç›¸å…³å»ºè®®æˆ–æ¨è\n\n"
        "è¦æ±‚ï¼šå†…å®¹è¯¦å®ï¼Œè¯­è¨€ç”ŸåŠ¨ï¼Œ300-500å­—ã€‚"
    )
    chain = prompt | llm
    return {"draft": chain.invoke({"topic": state["topic"]}).content}


def critique_content(state: ContentState):
    """å¯¹å†…å®¹è¿›è¡Œæ‰¹åˆ¤æ€§è¯„ä¼°"""
    prompt = PromptTemplate.from_template(
        "è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ‰¹åˆ¤æ€§åˆ†æå¹¶æå‡ºæ”¹è¿›å»ºè®®ï¼š\n\n{draft}\n\n"
        "è¯·ä»ä»¥ä¸‹è§’åº¦åˆ†æï¼š\n"
        "1. å†…å®¹å®Œæ•´æ€§\n"
        "2. é€»è¾‘ç»“æ„\n"
        "3. è¯­è¨€è¡¨è¾¾\n"
        "4. å®ç”¨æ€§\n"
        "æŒ‡å‡ºè‡³å°‘2é¡¹å¯æ”¹è¿›ä¹‹å¤„ã€‚"
    )
    chain = prompt | llm
    feedback = chain.invoke({"draft": state["draft"]})
    current_attempts = state.get("attempts", 0) + 1
    return {"corrections": [feedback.content], "attempts": current_attempts}


def refine_content(state: ContentState):
    """æ ¹æ®åé¦ˆä¿®æ­£å†…å®¹"""
    last_feedback = state["corrections"][-1]
    prompt = PromptTemplate.from_template(
        "è¯·æ ¹æ®ä»¥ä¸‹åé¦ˆé‡å†™å†…å®¹ï¼š\nåé¦ˆï¼š{feedback}\n\nåŸæ–‡ï¼š{draft}\n\n"
        "ä¿ç•™åŸæ–‡é£æ ¼ä½†è§£å†³åé¦ˆä¸­æåˆ°çš„é—®é¢˜ï¼Œç¡®ä¿å†…å®¹æ›´åŠ å®Œå–„ã€‚"
    )
    chain = prompt | llm
    new_draft = chain.invoke({"feedback": last_feedback, "draft": state["draft"]})
    return {"draft": new_draft.content}


def generate_image_prompt(state: ContentState):
    """æ ¹æ®å†…å®¹ç”Ÿæˆå›¾ç‰‡æç¤ºè¯"""
    prompt = PromptTemplate.from_template(
        "è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´çš„å›¾ç‰‡æè¿°ï¼Œç”¨äºç”Ÿæˆé…å›¾ï¼š\n\n{draft}\n\n"
        "è¦æ±‚ï¼š\n"
        "1. æè¿°è¦å…·ä½“ä¸”å¯Œæœ‰è§†è§‰æ„Ÿ\n"
        "2. çªå‡ºå†…å®¹çš„æ ¸å¿ƒä¸»é¢˜\n"
        "3. é€‚åˆç”Ÿæˆé«˜è´¨é‡çš„å›¾ç‰‡\n"
        "4. æ§åˆ¶åœ¨50å­—ä»¥å†…\n\n"
        "è¯·ç›´æ¥è¾“å‡ºå›¾ç‰‡æè¿°ï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜ã€‚"
    )
    chain = prompt | llm
    image_prompt = chain.invoke({"draft": state["draft"]}).content.strip()

    # ä½¿ç”¨æç¤ºè¯ä¼˜åŒ–å‡½æ•°
    enhanced_prompt = create_image_prompt(image_prompt, style="realistic")

    return {"image_prompt": enhanced_prompt}


def generate_images(state: ContentState):
    """ç”Ÿæˆé…å›¾"""
    generator = TextToImageGenerator()

    # ç”Ÿæˆå›¾ç‰‡
    image_paths = generator.generate_and_save(
        prompt=state["image_prompt"],
        method="dalle",
        size="1024x1024",
        quality="hd"
    )

    return {"image_paths": image_paths}


# ===== 3. æ„å»ºå·¥ä½œæµå›¾ =====
workflow = StateGraph(ContentState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("generate_content", generate_content_draft)
workflow.add_node("critique_content", critique_content)
workflow.add_node("refine_content", refine_content)
workflow.add_node("generate_image_prompt", generate_image_prompt)
workflow.add_node("generate_images", generate_images)

# è®¾ç½®å…¥å£ç‚¹
workflow.set_entry_point("generate_content")

# æ·»åŠ è¿‡æ¸¡è·¯å¾„
workflow.add_edge("generate_content", "critique_content")
workflow.add_edge("refine_content", "critique_content")
workflow.add_edge("critique_content", "generate_image_prompt")
workflow.add_edge("generate_image_prompt", "generate_images")


# æ·»åŠ æ¡ä»¶åˆ¤æ–­è¾¹
def should_continue_refinement(state: ContentState):
    """æ£€æŸ¥æ˜¯å¦éœ€è¦ç»§ç»­ä¿®æ­£å†…å®¹"""
    last_feedback = state["corrections"][-1].lower()

    # å¦‚æœæœ‰"æ»¡æ„"æˆ–"æ— éœ€ä¿®æ”¹"åˆ™ç»§ç»­åˆ°å›¾ç‰‡ç”Ÿæˆ
    if "æ»¡æ„" in last_feedback or "æ— éœ€ä¿®æ”¹" in last_feedback:
        return "generate_image_prompt"

    # æœ€å¤šå°è¯•3æ¬¡ä¿®æ­£
    return "refine_content" if state["attempts"] < 3 else "generate_image_prompt"


workflow.add_conditional_edges(
    "critique_content",
    should_continue_refinement,
    {"refine_content": "refine_content", "generate_image_prompt": "generate_image_prompt"}
)

# ç¼–è¯‘å›¾å½¢
graph = workflow.compile()


# ===== 4. æ‰§è¡Œå·¥ä½œæµ =====
def run_integrated_workflow(topic: str):
    """æ‰§è¡Œé›†æˆå·¥ä½œæµ"""
    print(f"\n{'=' * 60}")
    print(f"ğŸ¯ å¼€å§‹åˆ›ä½œä¸»é¢˜: {topic}")
    print(f"{'=' * 60}")

    # åˆå§‹åŒ–çŠ¶æ€
    state = {
        "topic": topic,
        "draft": "",
        "corrections": [],
        "image_prompt": "",
        "image_paths": [],
        "attempts": 0
    }

    # åˆ†æ­¥éª¤æ‰§è¡Œ
    for step, output in enumerate(graph.stream(state)):
        step_name = list(output.keys())[0]

        if step_name == "generate_content":
            print(f"\nğŸ“ [å†…å®¹è‰ç¨¿]:")
            print(f"{output[step_name]['draft']}")

        elif step_name == "critique_content":
            print(f"\nğŸ” [ç¬¬{output[step_name]['attempts']}è½®åé¦ˆ]:")
            print(f"{output[step_name]['corrections'][-1]}")

        elif step_name == "refine_content":
            print(f"\nâœï¸ [ä¿®æ­£åçš„å†…å®¹]:")
            print(f"{output[step_name]['draft']}")

        elif step_name == "generate_image_prompt":
            print(f"\nğŸ¨ [å›¾ç‰‡ç”Ÿæˆæç¤ºè¯]:")
            print(f"{output[step_name]['image_prompt']}")

        elif step_name == "generate_images":
            print(f"\nğŸ–¼ï¸ [å›¾ç‰‡ç”Ÿæˆç»“æœ]:")
            for path in output[step_name]['image_paths']:
                print(f"å›¾ç‰‡å·²ä¿å­˜: {path}")

    # æœ€ç»ˆç»“æœ
    final_state = graph.invoke(state)

    print(f"\n{'=' * 60}")
    print(f"ğŸ‰ åˆ›ä½œå®Œæˆï¼")
    print(f"{'=' * 60}")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - å†…å®¹ä¿®æ­£æ¬¡æ•°: {len(final_state['corrections'])}")
    print(f"   - ç”Ÿæˆå›¾ç‰‡æ•°é‡: {len(final_state['image_paths'])}")
    print(f"\nğŸ“ æœ€ç»ˆå†…å®¹:")
    print(f"{final_state['draft']}")
    print(f"\nğŸ¨ å›¾ç‰‡æç¤ºè¯:")
    print(f"{final_state['image_prompt']}")
    print(f"\nğŸ–¼ï¸ å›¾ç‰‡æ–‡ä»¶:")
    for path in final_state['image_paths']:
        print(f"  - {path}")


# ===== 5. è¿è¡Œç¤ºä¾‹ =====
if __name__ == "__main__":
    # ç¤ºä¾‹ï¼šåˆ›ä½œå…³äºç¾é£Ÿçš„å†…å®¹å’Œé…å›¾
    run_integrated_workflow("æœ‰ä»€ä¹ˆå¥½åƒçš„èåˆèœ,ç»™å‡ºæ¨è")
